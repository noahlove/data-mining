# Homework 3 Project

```{r include=FALSE}
library(MASS)

library(parallel)
library(doParallel)

cluster <- makeCluster(detectCores() - 1) # convention to leave 1 core for OS
registerDoParallel(cluster)

library(caret)

library(broom)
library(caret)
library(tidyverse)
library(factoextra)
```


```{r message=FALSE, warning=FALSE, include=FALSE}
tweets <- read_csv("Datasets/non_retweets_dc_inaug_steal.csv") %>% 
  drop_na()

```

## Question 0

Let's first see when these tweets were created:

```{r echo=FALSE}
ggplot(data = tweets, mapping = aes(x = created_at))+
  geom_histogram(fill = "steelblue", color = "black", bins = 23) + 
  theme_light() + 
  labs(title = "Twitter data pull by date", x = "Tweet Created On", y = "Count")

min(tweets$created_at)
max(tweets$created_at)


```

## Question 1



```{r}
df <- tweets %>% 
  dplyr::mutate(total = rowSums(dplyr::select(., contains('inaug')))) %>% 
  dplyr::select(-contains('inaug')) %>% 
  rename(inaug = total) %>% 
  dplyr::select(-created_at, -like_count, -reply_count, -retweet_count, -tweet_body)

mean(df$inaug)
```
This condensed seven columns and showed that 46.2% of the dataset's tweets contain the string "inaug."

```{r}
df$HASHTAG_stopthesteai

tweets_mini <- df %>% 
  dplyr::select(trump, inaug, `2021`, biden, steal, `2020`, HASHTAG_stopthest, HASHTAG_stopthesteai, HASHTAG_stopthesteai2020, HASHTAG_stopthesteai2021) %>% 
  top_n(n = 50)

tweets_mini
```


## Question 2

### Cross-validated OLS

```{r eval=FALSE, include=FALSE}
#test if it works
ols = lm(inaug ~ ., data = df)
summary(ols)
```


```{r message=FALSE, warning=FALSE, cache = TRUE}
train_control <- trainControl(method  = "cv", number = 5)
grid <- expand.grid(.fL = c(0), .usekernel = c(FALSE))

system.time(model_ols <- train(inaug ~ .,
                     data = df,
                     method = "lm",           # method
                     na.action = na.pass,     # pass missing
                     trControl = train_control))        # cross validation

```

Stepwise regression using AIC as the objective


```{r, cache = TRUE}
model_stepwise_mini <- train(inaug ~ .,
                        data = tweets_mini,
                        method = "glmStepAIC",
                        trControl = train_control)

model_stepwise_mini
```



```{r, cache=TRUE}
model_stepwise <- train(inaug ~ .,
                        data = df,
                        method = "glmStepAIC",
                        trControl = train_control)

model_stepwise
```
## 4) List out the top tokens corresponding to the strongest non-zero coefficients.



## 5) Function for Ridge regression

```{r}

```


### PCA on token

```{r}
pr_out <- prcomp(tweets, scale=FALSE)

```





